{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create functions in python to calculate the accuracy, precision, recall, and f1-score for two numpy arrays, a predicted value and a true value. You may use the following as a test for your functions:\n",
    "\n",
    "- x_predict = np.array(['red', 'blue', 'red', 'red', 'blue', 'blue', 'blue', 'red'])\n",
    "- x_true = np.array(['red', 'red', 'red', 'blue', 'blue', 'blue', 'red', 'red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_predict = np.array(['red', 'blue', 'red', 'red', 'blue', 'blue', 'blue', 'red'])\n",
    "x_true = np.array(['red', 'red', 'red', 'blue', 'blue', 'blue', 'red', 'red'])\n",
    "\n",
    "print(confusion_matrix(x_predict, x_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "def accuracy(x_predict, x_true):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(x_predict)):\n",
    "        if x_predict[i] == x_true[i]:\n",
    "            sum += 1\n",
    "    return sum/len(x_predict)\n",
    "\n",
    "print(accuracy(x_predict, x_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "def precision(x_predict, x_true, trueVal):\n",
    "    sum = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(x_predict)):\n",
    "        if x_predict[i] == trueVal:\n",
    "            total += 1\n",
    "        if (x_predict[i] == x_true[i] and x_predict[i] == trueVal):\n",
    "            sum += 1\n",
    "       \n",
    "    return sum/total\n",
    "\n",
    "print(precision(x_predict, x_true, 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "def recall(x_predict, x_true, trueVal):\n",
    "    sum = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(x_predict)):\n",
    "        if (x_true[i] == trueVal and x_predict[i] != trueVal):\n",
    "            total += 1\n",
    "        if (x_predict[i] == x_true[i] and x_predict[i] == trueVal):\n",
    "            sum += 1\n",
    "    \n",
    "    return sum/(sum + total)\n",
    "\n",
    "print(recall(x_predict, x_true, 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "def f1score(x_predict, x_true, trueVal):\n",
    "    p = precision(x_predict, x_true, trueVal)\n",
    "    r = recall(x_predict, x_true, trueVal)\n",
    "\n",
    "    return (2 * p * r) / (p + r)\n",
    "\n",
    "print(f1score(x_predict, x_true, 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTxt(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        content = file.read()\n",
    " \n",
    "        # Split the contents into lines\n",
    "        return content.splitlines()\n",
    " \n",
    "# Now 'lines' contains the lines of the file as elements of a list\n",
    "predicted = readTxt('predicted_values.txt')\n",
    "actual = readTxt('true_values.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n",
      "0.8620689655172413\n",
      "1.0\n",
      "0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predicted, actual))\n",
    "print(precision(predicted, actual, 'cold'))\n",
    "print(recall(predicted, actual, 'cold'))\n",
    "print(f1score(predicted, actual, 'cold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.84\n",
      "0.9130434782608696\n"
     ]
    }
   ],
   "source": [
    "print(precision(predicted, actual, 'hot'))\n",
    "print(recall(predicted, actual, 'hot'))\n",
    "print(f1score(predicted, actual, 'hot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([3, 7, 11, 15, 21])\n",
    "y_predict = np.array([2.5, 7.2, 11.0, 15.4, 20.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999999998\n"
     ]
    }
   ],
   "source": [
    "def mae(actual, calculated):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        sum += abs(calculated[i] - actual[i])\n",
    "\n",
    "    return sum/len(actual)\n",
    "\n",
    "print(mae(y_predict, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12199999999999984\n"
     ]
    }
   ],
   "source": [
    "def mse(actual, calculated):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        sum += pow((calculated[i] - actual[i]), 2)\n",
    "\n",
    "    return sum/len(actual)\n",
    "\n",
    "print(mse(y_predict, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6099999999999992\n"
     ]
    }
   ],
   "source": [
    "def sse(actual, calculated):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        sum += pow((calculated[i] - actual[i]), 2)\n",
    "\n",
    "    return sum\n",
    "\n",
    "print(sse(y_predict, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3492849839314594\n"
     ]
    }
   ],
   "source": [
    "def rmse(actual, calculated):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        sum += pow((calculated[i] - actual[i]), 2)\n",
    "\n",
    "    return np.sqrt(sum/len(actual))\n",
    "\n",
    "print(rmse(y_predict, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004099812244479047\n"
     ]
    }
   ],
   "source": [
    "def rmsle(actual, calculated):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        sum += np.log(((1 + calculated[i]) / (1 + actual[i])))\n",
    "\n",
    "    sum = sum / len(actual)\n",
    "    return np.sqrt(pow(sum/len(actual), 2))\n",
    "\n",
    "print(rmsle(y_predict, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('regression_data.csv', delimiter=',', skiprows=1)\n",
    "x = X[:,0]       # The x values for training\n",
    "y = X[:,1]       # The y values for training\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x.reshape(-1,1), y.reshape(-1,1))\n",
    "\n",
    "y_pred = lin_reg.predict(x.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.33471565]\n",
      "[98833.74975002]\n",
      "[494.16874875]\n",
      "[22.22990663]\n"
     ]
    }
   ],
   "source": [
    "print(mae(y, y_pred))\n",
    "print(sse(y, y_pred))\n",
    "print(mse(y, y_pred))\n",
    "print(rmse(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
